{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using deeper CNN on a small MNIST data set\n",
    "\n",
    "In this script we build deeper CNN with many convolutional layers. Like in the experiments with the fully connected NN with MNIST that we performed last time, we use again a small data with only 2400 images in the training data set so that the NN can be trained on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install sklearn ##for docker users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "import keras\n",
    "import sys\n",
    "print (\"Keras {} TF {} Python {}\".format(keras.__version__, tf.__version__, sys.version_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "X_train=x_train[0:2400]\n",
    "Y_train=y_train[0:2400]\n",
    "\n",
    "X_val=x_train[2400:3000]\n",
    "Y_val=y_train[2400:3000]\n",
    "\n",
    "X_test=x_test[0:1000]\n",
    "Y_test=y_test[0:1000]\n",
    "\n",
    "del x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.reshape(X_train, (2400,28,28,1))\n",
    "X_val=np.reshape(X_val, (600,28,28,1))\n",
    "X_test=np.reshape(X_test, (1000,28,28,1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[42,:,:,0],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToOneHot(vector, num_classes=None):\n",
    "    result = np.zeros((len(vector), num_classes), dtype='float32')\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result\n",
    "print(\"class label\")\n",
    "print(Y_train[0:5])\n",
    "print(\"class label in OneHot encodig\")\n",
    "print(convertToOneHot(Y_train[0:5], 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=convertToOneHot(Y_train,num_classes=10)\n",
    "print(Y_train.shape)\n",
    "Y_val=convertToOneHot(Y_val,num_classes=10)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we center and standardize the data\n",
    "X_mean = np.mean( X_train, axis = 0)\n",
    "X_std = np.std( X_train, axis = 0)\n",
    "\n",
    "X_train = (X_train - X_mean ) / (X_std + 0.0001)\n",
    "X_val = (X_val - X_mean ) / (X_std + 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we define  hyperparameter of the NN\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "img_rows, img_cols = 28, 28\n",
    "kernel_size = (3, 3)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "pool_size = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### a deeper CNN model\n",
    "name = 'cnn2'\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(8,kernel_size,padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(8, kernel_size,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Convolution2D(16, kernel_size,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# here is your code comming:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# end of your code\n",
    "\n",
    "model.add(Flatten())#macht einen vektor aus dem output\n",
    "model.add(Dense(40))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "        log_dir='tensorboard/mnist/' + name + '/', \n",
    "        write_graph=True,\n",
    "        histogram_freq=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(X_train, Y_train, \n",
    "                  batch_size=128, \n",
    "                  epochs=30,\n",
    "                  verbose=2, \n",
    "                  validation_data=(X_val, Y_val),\n",
    "                  callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = np.array((X_test - X_mean ) / (X_std + 0.0001),dtype=\"float32\")\n",
    "pred=model.predict(X_test_norm)\n",
    "print(confusion_matrix(Y_test,np.argmax(pred,axis=1)))\n",
    "print(\"Acc = \" ,np.sum(Y_test==np.argmax(pred,axis=1))/len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=tensorboard/tensorboard/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
